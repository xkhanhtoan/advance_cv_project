{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d86cdd-a038-4efd-a2bf-972e4262c5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- B·∫ÆT ƒê·∫¶U BENCHMARK TO√ÄN DI·ªÜN (ACCURACY + SPEED + SIZE) ---\n",
      "\n",
      "Evaluating: sroie_yolov8n_finetune...\n",
      "  -> Testing on SROIE_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 2.4¬±3.0 ms, read: 78.3¬±57.2 MB/s, size: 397.3 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/labels.cache... 347 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 347/347 17.1Mit/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0m/workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/images/X51005230659.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 44/44 15.0it/s 2.9s\n",
      "                   all        347      18704      0.962      0.958      0.978      0.708\n",
      "Speed: 0.7ms preprocess, 1.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "  -> Testing on Custom_Receipt_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 1.6¬±1.1 ms, read: 39.6¬±39.3 MB/s, size: 179.2 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/RECEIPT_YOLO_TRAIN/test/labels.cache... 122 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 122/122 3.2Mit/s 0.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 18.8it/s 0.9s\n",
      "                   all        122       4293      0.963      0.941      0.983      0.848\n",
      "Speed: 0.9ms preprocess, 2.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "\n",
      "Evaluating: sroie_yolov8m_finetune...\n",
      "  -> Testing on SROIE_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 5.5¬±6.9 ms, read: 170.8¬±151.5 MB/s, size: 772.0 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/labels.cache... 347 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 347/347 13.5Mit/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0m/workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/images/X51005230659.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 44/44 9.8it/s 4.5s\n",
      "                   all        347      18704      0.974      0.966      0.981      0.738\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "  -> Testing on Custom_Receipt_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.5¬±0.3 ms, read: 62.9¬±25.9 MB/s, size: 139.5 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/RECEIPT_YOLO_TRAIN/test/labels.cache... 122 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 122/122 4.3Mit/s 0.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 9.7it/s 1.7s\n",
      "                   all        122       4293      0.961      0.936      0.978      0.872\n",
      "Speed: 0.9ms preprocess, 9.3ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "\n",
      "Evaluating: sroie_yolov9c_finetune...\n",
      "  -> Testing on SROIE_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "YOLOv9c summary (fused): 156 layers, 25,320,019 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.8¬±0.5 ms, read: 112.7¬±46.2 MB/s, size: 298.7 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/labels.cache... 347 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 347/347 14.4Mit/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0m/workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/images/X51005230659.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 44/44 7.9it/s 5.6s\n",
      "                   all        347      18704      0.973      0.961      0.981      0.737\n",
      "Speed: 0.6ms preprocess, 10.5ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "  -> Testing on Custom_Receipt_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 3.7¬±6.6 ms, read: 27.6¬±17.4 MB/s, size: 157.6 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/RECEIPT_YOLO_TRAIN/test/labels.cache... 122 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 122/122 6.7Mit/s 0.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.9it/s 2.3s\n",
      "                   all        122       4293      0.969      0.945      0.983      0.951\n",
      "Speed: 0.9ms preprocess, 14.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "\n",
      "Evaluating: receipt_yolov8n_finetune...\n",
      "  -> Testing on SROIE_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.7¬±0.2 ms, read: 65.7¬±44.2 MB/s, size: 336.9 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/labels.cache... 347 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 347/347 17.1Mit/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0m/workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/images/X51005230659.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 44/44 15.4it/s 2.9s\n",
      "                   all        347      18704      0.912       0.87      0.924      0.582\n",
      "Speed: 0.7ms preprocess, 1.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "  -> Testing on Custom_Receipt_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.4¬±0.2 ms, read: 86.6¬±36.5 MB/s, size: 164.3 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/RECEIPT_YOLO_TRAIN/test/labels.cache... 122 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 122/122 6.5Mit/s 0.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 20.0it/s 0.8s\n",
      "                   all        122       4293      0.978      0.982      0.993       0.87\n",
      "Speed: 0.9ms preprocess, 2.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "\n",
      "Evaluating: receipt_yolov8m_finetune...\n",
      "  -> Testing on SROIE_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.5¬±0.2 ms, read: 278.1¬±195.0 MB/s, size: 1057.1 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/labels.cache... 347 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 347/347 9.6Mit/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0m/workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/images/X51005230659.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 44/44 10.0it/s 4.4s\n",
      "                   all        347      18704      0.921      0.894      0.935      0.606\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "  -> Testing on Custom_Receipt_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.6¬±0.2 ms, read: 82.4¬±37.5 MB/s, size: 208.9 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/RECEIPT_YOLO_TRAIN/test/labels.cache... 122 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 122/122 6.8Mit/s 0.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 9.8it/s 1.6s\n",
      "                   all        122       4293       0.98      0.981      0.992      0.883\n",
      "Speed: 0.7ms preprocess, 9.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "\n",
      "Evaluating: receipt_yolov9c_finetune...\n",
      "  -> Testing on SROIE_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "YOLOv9c summary (fused): 156 layers, 25,320,019 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.7¬±0.4 ms, read: 197.8¬±97.4 MB/s, size: 479.5 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/labels.cache... 347 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 347/347 17.3Mit/s 0.0s\n",
      "\u001B[34m\u001B[1mval: \u001B[0m/workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/test/images/X51005230659.jpg: 1 duplicate labels removed\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 44/44 7.9it/s 5.6s\n",
      "                   all        347      18704       0.92      0.891      0.933      0.583\n",
      "Speed: 0.6ms preprocess, 10.5ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "  -> Testing on Custom_Receipt_Test...\n",
      "Ultralytics 8.3.234 üöÄ Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA A40, 45403MiB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mFast image access ‚úÖ (ping: 0.8¬±0.7 ms, read: 96.8¬±70.7 MB/s, size: 268.1 KB)\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /workspace/advance_cv_project/Datasets/RECEIPT_YOLO_TRAIN/test/labels.cache... 122 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 122/122 9.5Mit/s 0.0s\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.2it/s 2.2s\n",
      "                   all        122       4293      0.983      0.985      0.993       0.87\n",
      "Speed: 0.8ms preprocess, 14.3ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "\n",
      "=== B·∫¢NG T·ªîNG H·ª¢P ===\n",
      "                       Model            Test_Data  mAP50-95 (%)  mAP50 (%)  Recall (%)  Precision (%)  Speed (ms)  Size (MB)  Params (M)\n",
      "5     sroie_yolov9c_finetune  Custom_Receipt_Test         95.11      98.34       94.51          96.92       14.24      49.22       25.53\n",
      "9   receipt_yolov8m_finetune  Custom_Receipt_Test         88.34      99.22       98.08          98.04        9.28      49.64       25.86\n",
      "3     sroie_yolov8m_finetune  Custom_Receipt_Test         87.21      97.83       93.55          96.10        9.28      49.63       25.86\n",
      "11  receipt_yolov9c_finetune  Custom_Receipt_Test         87.05      99.29       98.48          98.33       14.25      49.22       25.53\n",
      "7   receipt_yolov8n_finetune  Custom_Receipt_Test         86.98      99.29       98.18          97.79        2.24       5.98        3.01\n",
      "1     sroie_yolov8n_finetune  Custom_Receipt_Test         84.77      98.25       94.14          96.26        2.25       5.97        3.01\n",
      "2     sroie_yolov8m_finetune           SROIE_Test         73.81      98.08       96.60          97.36        6.99      49.63       25.86\n",
      "4     sroie_yolov9c_finetune           SROIE_Test         73.69      98.07       96.12          97.30       10.50      49.22       25.53\n",
      "0     sroie_yolov8n_finetune           SROIE_Test         70.85      97.78       95.75          96.19        1.74       5.97        3.01\n",
      "8   receipt_yolov8m_finetune           SROIE_Test         60.55      93.45       89.40          92.07        6.98      49.64       25.86\n",
      "10  receipt_yolov9c_finetune           SROIE_Test         58.28      93.29       89.10          91.99       10.51      49.22       25.53\n",
      "6   receipt_yolov8n_finetune           SROIE_Test         58.21      92.41       87.01          91.16        1.73       5.98        3.01\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "MODELS_DIR = '/workspace/advance_cv_project/train/runs/detect'\n",
    "\n",
    "# Danh s√°ch 6 model c·ªßa b·∫°n\n",
    "model_names = [\n",
    "    'sroie_yolov8n_finetune', 'sroie_yolov8m_finetune', 'sroie_yolov9c_finetune',\n",
    "    'receipt_yolov8n_finetune', 'receipt_yolov8m_finetune', 'receipt_yolov9c_finetune'\n",
    "]\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n data test\n",
    "DATASETS = {\n",
    "    'SROIE_Test': '/workspace/advance_cv_project/Datasets/SROIE_YOLO_TRAIN/data.yaml',\n",
    "    'Custom_Receipt_Test': '/workspace/advance_cv_project/Datasets/RECEIPT_YOLO_TRAIN/data.yaml' \n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"--- B·∫ÆT ƒê·∫¶U BENCHMARK TO√ÄN DI·ªÜN (ACCURACY + SPEED + SIZE) ---\")\n",
    "\n",
    "for model_folder in model_names:\n",
    "    weights_path = os.path.join(MODELS_DIR, model_folder, 'weights', 'best.pt')\n",
    "    \n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f\"Skipping {model_folder} (Not found)\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nEvaluating: {model_folder}...\")\n",
    "    try:\n",
    "        # 1. Load Model\n",
    "        model = YOLO(weights_path)\n",
    "        \n",
    "        # 2. L·∫•y th√¥ng tin k√≠ch th∆∞·ªõc File (Size MB)\n",
    "        size_mb = os.path.getsize(weights_path) / (1024 * 1024)\n",
    "        \n",
    "        # 3. L·∫•y s·ªë l∆∞·ª£ng tham s·ªë (Params)\n",
    "        # model.info() tr·∫£ v·ªÅ (layers, params, gradients, flops)\n",
    "        n_params = sum(x.numel() for x in model.parameters()) / 1e6 # Tri·ªáu tham s·ªë\n",
    "        \n",
    "        # 4. Ch·∫°y ƒë√°nh gi√° tr√™n t·ª´ng t·∫≠p d·ªØ li·ªáu\n",
    "        for dataset_name, yaml_path in DATASETS.items():\n",
    "            print(f\"  -> Testing on {dataset_name}...\")\n",
    "            \n",
    "            # Ch·∫°y Val/Test\n",
    "            metrics = model.val(\n",
    "                data=yaml_path,\n",
    "                split='test',\n",
    "                imgsz=1024,\n",
    "                batch=8,\n",
    "                verbose=False,\n",
    "                plots=False\n",
    "            )\n",
    "            \n",
    "            # 5. L·∫•y T·ªëc ƒë·ªô (Inference Time)\n",
    "            # metrics.speed tr·∫£ v·ªÅ dictionary {'preprocess': ..., 'inference': ..., 'postprocess': ...}\n",
    "            inference_time = metrics.speed['inference']\n",
    "            \n",
    "            results.append({\n",
    "                'Model': model_folder,\n",
    "                'Test_Data': dataset_name,\n",
    "                \n",
    "                # --- NH√ìM CH·∫§T L∆Ø·ª¢NG ---\n",
    "                'mAP50-95 (%)': round(metrics.box.map * 100, 2),\n",
    "                'mAP50 (%)': round(metrics.box.map50 * 100, 2),\n",
    "                'Recall (%)': round(metrics.box.mr * 100, 2),\n",
    "                'Precision (%)': round(metrics.box.mp * 100, 2),\n",
    "                \n",
    "                # --- NH√ìM HI·ªÜU NƒÇNG ---\n",
    "                'Speed (ms)': round(inference_time, 2),\n",
    "                'Size (MB)': round(size_mb, 2),\n",
    "                'Params (M)': round(n_params, 2)\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  -> L·ªói: {e}\")\n",
    "\n",
    "# Xu·∫•t k·∫øt qu·∫£\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# S·∫Øp x·∫øp theo Data Test r·ªìi ƒë·∫øn mAP50-95\n",
    "df = df.sort_values(by=['Test_Data', 'mAP50-95 (%)'], ascending=[True, False])\n",
    "\n",
    "print(\"\\n=== B·∫¢NG T·ªîNG H·ª¢P ===\")\n",
    "print(df.to_string())\n",
    "\n",
    "# df.to_csv('final_full_benchmark.csv', index=False)\n",
    "# print(\"\\nƒê√£ l∆∞u k·∫øt qu·∫£ v√†o 'final_full_benchmark.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
