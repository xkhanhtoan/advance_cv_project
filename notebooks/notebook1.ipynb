{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T01:20:24.903334900Z",
     "start_time": "2026-01-18T01:20:00.886108700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Dict, List\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- Cấu hình đường dẫn ---\n",
    "# Thêm thư mục gốc vào path để import được utils\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# 1. Import Sanitizer (Theo đúng code của bạn)\n",
    "try:\n",
    "    from utils.sanitizer import SmartSanitizer\n",
    "except ImportError:\n",
    "    # Fallback nếu path chưa đúng, nhưng trong notebook của bạn đã chạy được thì dòng trên sẽ OK\n",
    "    print(\"CẢNH BÁO: Không tìm thấy file utils/sanitizer.py\")\n",
    "    class SmartSanitizer:\n",
    "        @staticmethod\n",
    "        def sanitize(x): return x\n",
    "\n",
    "# 2. Import VietOCR & Transformer\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "from transformers import LayoutLMv3ForTokenClassification, LayoutLMv3Processor\n",
    "\n",
    "# ==============================================================================\n",
    "# PHẦN 1: CLASS KIE (GIỮ NGUYÊN CODE CỦA BẠN)\n",
    "# ==============================================================================\n",
    "\n",
    "class SROIEInference:\n",
    "    \"\"\"Inference cho LayoutLMv3 trên SROIE receipts (kèm Auto-Cleaning)\"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str, device=None):\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Load model và processor\n",
    "        print(f\"Loading KIE model from {model_path} to {self.device}...\")\n",
    "        self.model = LayoutLMv3ForTokenClassification.from_pretrained(model_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.processor = LayoutLMv3Processor.from_pretrained(\n",
    "            model_path,\n",
    "            apply_ocr=False\n",
    "        )\n",
    "\n",
    "        # Load label mappings\n",
    "        label_file = os.path.join(model_path, 'label2id.json')\n",
    "        if os.path.exists(label_file):\n",
    "            with open(label_file, 'r') as f:\n",
    "                self.label2id = json.load(f)\n",
    "            self.id2label = {int(v): k for k, v in self.label2id.items()}\n",
    "        else:\n",
    "            self.label2id = {\n",
    "                \"O\": 0, \"B-COMPANY\": 1, \"I-COMPANY\": 2, \"B-DATE\": 3, \"I-DATE\": 4,\n",
    "                \"B-ADDRESS\": 5, \"I-ADDRESS\": 6, \"B-TOTAL\": 7, \"I-TOTAL\": 8\n",
    "            }\n",
    "            self.id2label = {v: k for k, v in self.label2id.items()}\n",
    "\n",
    "    def predict_single(self, image_path: str, words: List[str], boxes: List[List[int]]) -> Dict[str, str]:\n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        width, height = image.size\n",
    "\n",
    "        # Normalize boxes (0-1000)\n",
    "        normalized_boxes = [\n",
    "            [\n",
    "                int(1000 * box[0] / width),\n",
    "                int(1000 * box[1] / height),\n",
    "                int(1000 * box[2] / width),\n",
    "                int(1000 * box[3] / height)\n",
    "            ]\n",
    "            for box in boxes\n",
    "        ]\n",
    "\n",
    "        # Encode\n",
    "        encoding = self.processor(\n",
    "            image,\n",
    "            words,\n",
    "            boxes=normalized_boxes,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        word_ids = encoding.word_ids(batch_index=0)\n",
    "        input_data = {k: v.to(self.device) for k, v in encoding.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**input_data)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "        predictions = predictions.cpu().numpy()[0]\n",
    "\n",
    "        word_predictions = []\n",
    "        previous_word_idx = None\n",
    "\n",
    "        for idx, word_idx in enumerate(word_ids):\n",
    "            if word_idx is not None and word_idx != previous_word_idx:\n",
    "                word_predictions.append({\n",
    "                    'word': words[word_idx],\n",
    "                    'label': self.id2label[predictions[idx]]\n",
    "                })\n",
    "                previous_word_idx = word_idx\n",
    "\n",
    "        entities = self.extract_entities(word_predictions)\n",
    "        return entities\n",
    "\n",
    "    def extract_entities(self, word_predictions: List[Dict]) -> Dict[str, str]:\n",
    "        entities = {'company': '', 'date': '', 'address': '', 'total': ''}\n",
    "        current_entity = None\n",
    "        current_text = []\n",
    "\n",
    "        for item in word_predictions:\n",
    "            word = item['word']\n",
    "            label = item['label']\n",
    "\n",
    "            if label.startswith('B-'):\n",
    "                if current_entity and current_text:\n",
    "                    entities[current_entity.lower()] = ' '.join(current_text)\n",
    "                current_entity = label[2:]\n",
    "                current_text = [word]\n",
    "\n",
    "            elif label.startswith('I-'):\n",
    "                entity_name = label[2:]\n",
    "                if entity_name == current_entity:\n",
    "                    current_text.append(word)\n",
    "                else:\n",
    "                    if current_entity and current_text:\n",
    "                         entities[current_entity.lower()] = ' '.join(current_text)\n",
    "                    current_entity = entity_name\n",
    "                    current_text = [word]\n",
    "            else:\n",
    "                if current_entity and current_text:\n",
    "                    entities[current_entity.lower()] = ' '.join(current_text)\n",
    "                current_entity = None\n",
    "                current_text = []\n",
    "\n",
    "        if current_entity and current_text:\n",
    "            entities[current_entity.lower()] = ' '.join(current_text)\n",
    "\n",
    "        clean_entities = SmartSanitizer.sanitize(entities)\n",
    "        return clean_entities\n",
    "\n",
    "# ==============================================================================\n",
    "# PHẦN 2: PIPELINE TÍCH HỢP (YOLO + VietOCR -> gọi SROIEInference)\n",
    "# ==============================================================================\n",
    "\n",
    "class EndToEndPipeline:\n",
    "    def __init__(self, yolo_path, kie_model_path, device='cpu'):\n",
    "        self.device = device\n",
    "\n",
    "        # 1. Khởi tạo YOLO\n",
    "        print(f\"--- Loading YOLO from {yolo_path} ---\")\n",
    "        self.yolo_model = YOLO(yolo_path)\n",
    "\n",
    "        # 2. Khởi tạo VietOCR (Dùng vgg_transformer như bạn yêu cầu)\n",
    "        print(\"--- Loading VietOCR (vgg_transformer) ---\")\n",
    "        config = Cfg.load_config_from_name('vgg_transformer')\n",
    "        config['device'] = device\n",
    "        config['predictor']['beamsearch'] = False\n",
    "        config['cnn']['pretrained'] = False\n",
    "        self.ocr_model = Predictor(config)\n",
    "\n",
    "        # 3. Khởi tạo KIE (Dùng class của bạn)\n",
    "        # Lưu ý: SROIEInference tự load model bên trong __init__\n",
    "        self.kie_engine = SROIEInference(model_path=kie_model_path, device=device)\n",
    "\n",
    "    def run(self, image_path):\n",
    "        print(f\"\\n>>> Processing: {os.path.basename(image_path)}\")\n",
    "\n",
    "        # A. Detect Text (YOLO)\n",
    "        # Đọc ảnh bằng OpenCV để crop cho chính xác\n",
    "        img_cv = cv2.imread(image_path)\n",
    "        if img_cv is None:\n",
    "            print(\"Error: Image not found.\")\n",
    "            return {}\n",
    "\n",
    "        results = self.yolo_model(image_path, verbose=False)\n",
    "\n",
    "        detected_data = [] # Lưu trữ {box, text}\n",
    "\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                # Lấy tọa độ x1, y1, x2, y2\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "                # Check biên ảnh\n",
    "                h, w, _ = img_cv.shape\n",
    "                x1, y1 = max(0, x1), max(0, y1)\n",
    "                x2, y2 = min(w, x2), min(h, y2)\n",
    "\n",
    "                # Crop ảnh\n",
    "                crop = img_cv[y1:y2, x1:x2]\n",
    "                if crop.size == 0: continue\n",
    "\n",
    "                # B. Recognize Text (VietOCR)\n",
    "                # Chuyển BGR (OpenCV) -> RGB -> PIL\n",
    "                crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                try:\n",
    "                    text = self.ocr_model.predict(crop_pil)\n",
    "                except:\n",
    "                    text = \"\"\n",
    "\n",
    "                if text.strip():\n",
    "                    detected_data.append({\n",
    "                        \"box\": [x1, y1, x2, y2],\n",
    "                        \"text\": text\n",
    "                    })\n",
    "\n",
    "        if not detected_data:\n",
    "            print(\"No text detected.\")\n",
    "            return {}\n",
    "\n",
    "        # C. Chuẩn bị dữ liệu cho KIE\n",
    "        # QUAN TRỌNG: Sort box từ trên xuống dưới, trái sang phải\n",
    "        detected_data.sort(key=lambda k: (k['box'][1], k['box'][0]))\n",
    "\n",
    "        words = [item['text'] for item in detected_data]\n",
    "        boxes = [item['box'] for item in detected_data]\n",
    "\n",
    "        print(f\"-> Detected {len(words)} words. Running KIE...\")\n",
    "\n",
    "        # D. Gọi model KIE của bạn\n",
    "        # Hàm predict_single của bạn nhận vào image_path (string)\n",
    "        final_result = self.kie_engine.predict_single(image_path, words, boxes)\n",
    "\n",
    "        return final_result\n",
    "\n",
    "# ==============================================================================\n",
    "# PHẦN 3: CHẠY THỬ\n",
    "# ==============================================================================\n",
    "\n",
    "# Cấu hình Path\n",
    "YOLO_WEIGHTS = r'D:\\ADMIN\\Documents\\Classwork\\advance_cv_project\\train\\runs\\detect\\sroie_yolov8m_finetune\\weights\\best.pt'\n",
    "KIE_MODEL_DIR = r'D:\\ADMIN\\Documents\\Classwork\\advance_cv_project\\train\\layoutlmv3_sroie_output\\best_model'\n",
    "TEST_IMAGE = r'D:\\ADMIN\\Documents\\Classwork\\advance_cv_project\\data\\Receipt_OCR_1\\raw\\A0011.png'\n",
    "\n",
    "# Chạy\n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(TEST_IMAGE):\n",
    "        # Khởi tạo Pipeline\n",
    "        pipeline = EndToEndPipeline(YOLO_WEIGHTS, KIE_MODEL_DIR, device='cpu')\n",
    "\n",
    "        # Dự đoán\n",
    "        result = pipeline.run(TEST_IMAGE)\n",
    "\n",
    "        print(\"\\n=== FINAL RESULT ===\")\n",
    "        print(json.dumps(result, indent=4, ensure_ascii=False))\n",
    "    else:\n",
    "        print(f\"File ảnh không tồn tại: {TEST_IMAGE}\")"
   ],
   "id": "98fa664b80b272c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OS\\.conda\\envs\\py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading YOLO from D:\\ADMIN\\Documents\\Classwork\\advance_cv_project\\train\\runs\\detect\\sroie_yolov8m_finetune\\weights\\best.pt ---\n",
      "--- Loading VietOCR (vgg_transformer) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OS\\.conda\\envs\\py3.11\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weight C:\\Users\\OS\\AppData\\Local\\Temp\\vgg_transformer.pth exsits. Ignore download!\n",
      "Loading KIE model from D:\\ADMIN\\Documents\\Classwork\\advance_cv_project\\train\\layoutlmv3_sroie_output\\best_model to cpu...\n",
      "\n",
      ">>> Processing: A0011.png\n",
      "-> Detected 35 words. Running KIE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OS\\.conda\\envs\\py3.11\\Lib\\site-packages\\transformers\\modeling_utils.py:1742: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL RESULT ===\n",
      "{\n",
      "    \"company\": \"VM% QNH Dư án KDC lấn biển coc 6\",\n",
      "    \"date\": \"14/08/2020\",\n",
      "    \"address\": \"TP. Câm Phà, T, Quảng Ninh\",\n",
      "    \"total\": \"41.000\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b83fdf96b618210"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
